{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def make_random_bin(length):\n",
    "\t\treturn \"\".join([str(random.randint(0, 1)) for i in range(length)])\n",
    "\n",
    "def add_bin(a: str, b: str):\n",
    "\t\tans = bin(int(a[::-1], 2) + int(b[::-1], 2))[2:]\n",
    "\t\t# Pad with zeros\n",
    "\t\tans = \"0\" * (len(a) - len(ans)) + ans\n",
    "\t\treturn ans[::-1]\n",
    "\n",
    "def convert_decimal_to_normalized_binary(a: int, b: int):\n",
    "\t# Convert the numbers to binary\n",
    "\tnum1 = bin(a)[2:]\n",
    "\tnum2 = bin(b)[2:]\n",
    "\n",
    "\t# Pad the numbers with zeros so that they are of the same length\n",
    "\tif len(num1) > len(num2):\n",
    "\t\tnum2 = \"0\" * (len(num1) - len(num2)) + num2\n",
    "\telif len(num2) > len(num1):\n",
    "\t\tnum1 = \"0\" * (len(num2) - len(num1)) + num1\n",
    "\n",
    "\t# Reverse the numbers\n",
    "\tnum1 = num1[::-1] + \"0\"\n",
    "\tnum2 = num2[::-1] + \"0\"\n",
    "\n",
    "\treturn num1, num2\n",
    "\n",
    "def convert_normalized_binary_to_decimal(bin: str):\n",
    "\t# Reverse the output\n",
    "\tbin = bin[::-1]\n",
    "\n",
    "\t# Convert the output to a number\n",
    "\treturn int(\"\".join(bin), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(Dataset):\n",
    "\tdef __init__(self, seq_length, num_bits):\n",
    "\t\tself.seq_length = seq_length\n",
    "\t\tself.num_bits = num_bits\n",
    "\t\tself.seq1 = make_random_bin(seq_length)\n",
    "\t\tself.seq2 = make_random_bin(seq_length)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tsample1 = self.seq1[index:index + self.num_bits - 1] + \"0\"\n",
    "\t\tsample2 = self.seq2[index:index + self.num_bits - 1] + \"0\"\n",
    "\t\tinput = torch.tensor([[int(x, 2) for x in sample1], [int(x, 2) for x in sample2]])\n",
    "\t\tinput = torch.transpose(input, 0, 1).float()\n",
    "\t\toutput = torch.tensor([int(x, 2) for x in add_bin(sample1, sample2)])\n",
    "\t\treturn input, output\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.seq_length - self.num_bits + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 0.]]), tensor([1, 1, 0, 1, 0]))\n"
     ]
    }
   ],
   "source": [
    "data = BinaryDataset(3 * 128, 5)\n",
    "test_dataloader = DataLoader(dataset=data, batch_size=128)\n",
    "print(data.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class Model(nn.Module):\n",
    "\tdef __init__(self) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.input_size = 2 # Passing two binary bits\n",
    "\t\tself.hidden_dim = 10\n",
    "\t\tself.output_size = 1 # Returning 1 bit binary sum\n",
    "\n",
    "\t\tself.rnn = nn.RNN(\n",
    "\t\t\tinput_size=self.input_size,\n",
    "\t\t\thidden_size=self.hidden_dim,\n",
    "\t\t\tbatch_first=True\n",
    "\t\t)\n",
    "\t\tself.fc = nn.Linear(self.hidden_dim, self.output_size)\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# X is of shape (batch_size, sequence_length, input_dim = 2)\n",
    "\t\tout, _ = self.rnn(x)\n",
    "\n",
    "\t\t# out is shape (batch_size, sequence_length, hidden_dim = 10)\n",
    "\n",
    "\t\tout = self.fc(out)\n",
    "\n",
    "\t\tout = self.sigmoid(out)\n",
    "\n",
    "\t\t# out is now of shape (batch_size, sequence_length, output_dim = 1)\n",
    "\n",
    "\t\t# Transform output to size (batch_size, sequence_length)\n",
    "\t\tout = out.squeeze()\n",
    "\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 5]) torch.Size([128, 5])\n",
      "Input tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 0.]])\n",
      "Sum tensor([1, 1, 0, 1, 0])\n",
      "Output tensor([0.5111, 0.4795, 0.5527, 0.6154, 0.5409], grad_fn=<SelectBackward0>)\n",
      "0.4703125\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Model()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "# Test the model's accuracy\n",
    "def compute_accuracy(label, pred):\n",
    "\tpred = torch.round(pred)\n",
    "\t# Pred is of size (batch_size, sequence_length)\n",
    "\t# Label is of size (batch_size, sequence_length)\n",
    "\treturn torch.sum(label == pred).item() / (len(label) * len(label[0]))\n",
    "\n",
    "\n",
    "# Try the model on random data\n",
    "x, label = next(iter(test_dataloader))\n",
    "out = model(x)\n",
    "print(out.shape, label.shape)\n",
    "print(\"Input\", x[0])\n",
    "print(\"Sum\",  label[0])\n",
    "print(\"Output\", out[0])\n",
    "print(compute_accuracy(label, out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Loss: 0.7007, Accuracy: 47.03%\n",
      "Epoch [0/100], Loss: 0.7376, Accuracy: 51.41%\n",
      "Epoch [0/100], Loss: 0.6969, Accuracy: 47.10%\n",
      "Epoch [1/100], Loss: 0.6934, Accuracy: 51.25%\n",
      "Epoch [1/100], Loss: 0.6981, Accuracy: 49.22%\n",
      "Epoch [1/100], Loss: 0.6916, Accuracy: 46.13%\n",
      "Epoch [2/100], Loss: 0.7003, Accuracy: 48.75%\n",
      "Epoch [2/100], Loss: 0.6894, Accuracy: 55.31%\n",
      "Epoch [2/100], Loss: 0.6938, Accuracy: 54.35%\n",
      "Epoch [3/100], Loss: 0.6963, Accuracy: 53.91%\n",
      "Epoch [3/100], Loss: 0.6828, Accuracy: 49.06%\n",
      "Epoch [3/100], Loss: 0.7065, Accuracy: 48.71%\n",
      "Epoch [4/100], Loss: 0.6847, Accuracy: 54.22%\n",
      "Epoch [4/100], Loss: 0.6751, Accuracy: 63.59%\n",
      "Epoch [4/100], Loss: 0.6929, Accuracy: 47.90%\n",
      "Epoch [5/100], Loss: 0.6846, Accuracy: 57.50%\n",
      "Epoch [5/100], Loss: 0.6718, Accuracy: 60.00%\n",
      "Epoch [5/100], Loss: 0.6947, Accuracy: 52.74%\n",
      "Epoch [6/100], Loss: 0.6849, Accuracy: 53.28%\n",
      "Epoch [6/100], Loss: 0.6652, Accuracy: 61.25%\n",
      "Epoch [6/100], Loss: 0.6896, Accuracy: 59.68%\n",
      "Epoch [7/100], Loss: 0.6788, Accuracy: 60.31%\n",
      "Epoch [7/100], Loss: 0.6561, Accuracy: 68.91%\n",
      "Epoch [7/100], Loss: 0.6835, Accuracy: 61.61%\n",
      "Epoch [8/100], Loss: 0.6697, Accuracy: 61.88%\n",
      "Epoch [8/100], Loss: 0.6449, Accuracy: 69.38%\n",
      "Epoch [8/100], Loss: 0.6751, Accuracy: 55.48%\n",
      "Epoch [9/100], Loss: 0.6498, Accuracy: 65.47%\n",
      "Epoch [9/100], Loss: 0.6237, Accuracy: 72.66%\n",
      "Epoch [9/100], Loss: 0.6497, Accuracy: 67.58%\n",
      "Epoch [10/100], Loss: 0.6274, Accuracy: 70.16%\n",
      "Epoch [10/100], Loss: 0.5870, Accuracy: 77.19%\n",
      "Epoch [10/100], Loss: 0.6020, Accuracy: 72.74%\n",
      "Epoch [11/100], Loss: 0.5791, Accuracy: 72.19%\n",
      "Epoch [11/100], Loss: 0.5330, Accuracy: 78.44%\n",
      "Epoch [11/100], Loss: 0.5378, Accuracy: 79.03%\n",
      "Epoch [12/100], Loss: 0.5086, Accuracy: 82.66%\n",
      "Epoch [12/100], Loss: 0.4677, Accuracy: 89.38%\n",
      "Epoch [12/100], Loss: 0.4447, Accuracy: 90.16%\n",
      "Epoch [13/100], Loss: 0.4442, Accuracy: 87.97%\n",
      "Epoch [13/100], Loss: 0.3494, Accuracy: 96.09%\n",
      "Epoch [13/100], Loss: 0.3824, Accuracy: 91.13%\n",
      "Epoch [14/100], Loss: 0.3137, Accuracy: 97.50%\n",
      "Epoch [14/100], Loss: 0.2817, Accuracy: 97.19%\n",
      "Epoch [14/100], Loss: 0.2338, Accuracy: 99.52%\n",
      "Epoch [15/100], Loss: 0.2168, Accuracy: 97.97%\n",
      "Epoch [15/100], Loss: 0.1683, Accuracy: 98.44%\n",
      "Epoch [15/100], Loss: 0.1440, Accuracy: 100.00%\n",
      "Epoch [16/100], Loss: 0.1335, Accuracy: 99.38%\n",
      "Epoch [16/100], Loss: 0.1090, Accuracy: 99.84%\n",
      "Epoch [16/100], Loss: 0.0955, Accuracy: 100.00%\n",
      "Epoch [17/100], Loss: 0.0797, Accuracy: 100.00%\n",
      "Epoch [17/100], Loss: 0.0651, Accuracy: 100.00%\n",
      "Epoch [17/100], Loss: 0.0558, Accuracy: 100.00%\n",
      "Epoch [18/100], Loss: 0.0492, Accuracy: 99.84%\n",
      "Epoch [18/100], Loss: 0.0448, Accuracy: 100.00%\n",
      "Epoch [18/100], Loss: 0.0344, Accuracy: 100.00%\n",
      "Epoch [19/100], Loss: 0.0304, Accuracy: 100.00%\n",
      "Epoch [19/100], Loss: 0.0269, Accuracy: 100.00%\n",
      "Epoch [19/100], Loss: 0.0257, Accuracy: 100.00%\n",
      "Epoch [20/100], Loss: 0.0223, Accuracy: 100.00%\n",
      "Epoch [20/100], Loss: 0.0188, Accuracy: 100.00%\n",
      "Epoch [20/100], Loss: 0.0180, Accuracy: 100.00%\n",
      "Epoch [21/100], Loss: 0.0163, Accuracy: 100.00%\n",
      "Epoch [21/100], Loss: 0.0143, Accuracy: 100.00%\n",
      "Epoch [21/100], Loss: 0.0135, Accuracy: 100.00%\n",
      "Epoch [22/100], Loss: 0.0117, Accuracy: 100.00%\n",
      "Epoch [22/100], Loss: 0.0103, Accuracy: 100.00%\n",
      "Epoch [22/100], Loss: 0.0107, Accuracy: 100.00%\n",
      "Epoch [23/100], Loss: 0.0093, Accuracy: 100.00%\n",
      "Epoch [23/100], Loss: 0.0082, Accuracy: 100.00%\n",
      "Epoch [23/100], Loss: 0.0083, Accuracy: 100.00%\n",
      "Epoch [24/100], Loss: 0.0074, Accuracy: 100.00%\n",
      "Epoch [24/100], Loss: 0.0064, Accuracy: 100.00%\n",
      "Epoch [24/100], Loss: 0.0067, Accuracy: 100.00%\n",
      "Epoch [25/100], Loss: 0.0062, Accuracy: 100.00%\n",
      "Epoch [25/100], Loss: 0.0053, Accuracy: 100.00%\n",
      "Epoch [25/100], Loss: 0.0056, Accuracy: 100.00%\n",
      "Epoch [26/100], Loss: 0.0051, Accuracy: 100.00%\n",
      "Epoch [26/100], Loss: 0.0046, Accuracy: 100.00%\n",
      "Epoch [26/100], Loss: 0.0048, Accuracy: 100.00%\n",
      "Epoch [27/100], Loss: 0.0045, Accuracy: 100.00%\n",
      "Epoch [27/100], Loss: 0.0040, Accuracy: 100.00%\n",
      "Epoch [27/100], Loss: 0.0042, Accuracy: 100.00%\n",
      "Epoch [28/100], Loss: 0.0039, Accuracy: 100.00%\n",
      "Epoch [28/100], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [28/100], Loss: 0.0037, Accuracy: 100.00%\n",
      "Epoch [29/100], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [29/100], Loss: 0.0032, Accuracy: 100.00%\n",
      "Epoch [29/100], Loss: 0.0034, Accuracy: 100.00%\n",
      "Epoch [30/100], Loss: 0.0032, Accuracy: 100.00%\n",
      "Epoch [30/100], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [30/100], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [31/100], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [31/100], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [31/100], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [32/100], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [32/100], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [32/100], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [33/100], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [33/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [33/100], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [34/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [34/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [34/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [35/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [35/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [35/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [36/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [36/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [36/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [37/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [37/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [37/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [38/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [38/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [38/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [39/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [39/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [39/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [40/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [40/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [40/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [41/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [41/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [41/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [42/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [42/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [42/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [43/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [43/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [43/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [44/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [44/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [44/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [45/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [45/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [45/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [46/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [46/100], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [46/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [47/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [47/100], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [47/100], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [48/100], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [48/100], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [48/100], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [49/100], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [49/100], Loss: 0.0013, Accuracy: 100.00%\n",
      "Epoch [49/100], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [50/100], Loss: 0.0013, Accuracy: 100.00%\n",
      "Epoch [50/100], Loss: 0.0013, Accuracy: 100.00%\n",
      "Epoch [50/100], Loss: 0.0013, Accuracy: 100.00%\n",
      "Epoch [51/100], Loss: 0.0013, Accuracy: 100.00%\n",
      "Epoch [51/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [51/100], Loss: 0.0013, Accuracy: 100.00%\n",
      "Epoch [52/100], Loss: 0.0013, Accuracy: 100.00%\n",
      "Epoch [52/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [52/100], Loss: 0.0013, Accuracy: 100.00%\n",
      "Epoch [53/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [53/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [53/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [54/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [54/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [54/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [55/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [55/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [55/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [56/100], Loss: 0.0012, Accuracy: 100.00%\n",
      "Epoch [56/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [56/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [57/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [57/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [57/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [58/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [58/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [58/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [59/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [59/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [59/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [60/100], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [60/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [60/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [61/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [61/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [61/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [62/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [62/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [62/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [63/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [63/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [63/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [64/100], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [64/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [64/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [65/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [65/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [65/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [66/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [66/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [66/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [67/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [67/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [67/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [68/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [68/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [68/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [69/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [69/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [69/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [70/100], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [70/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [70/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [71/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [71/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [71/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [72/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [72/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [72/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [73/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [73/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [73/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [74/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [74/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [74/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [75/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [75/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [75/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [76/100], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [76/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [76/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [77/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [77/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [77/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [78/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [78/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [78/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [79/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [79/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [79/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [80/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [80/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [80/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [81/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [81/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [81/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [82/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [82/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [82/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [83/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [83/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [83/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [84/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [84/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [84/100], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [85/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [85/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [85/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [86/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [86/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [86/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [87/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [87/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [87/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [88/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [88/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [88/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [89/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [89/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [89/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [90/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [90/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [90/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [91/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [91/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [91/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [92/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [92/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [92/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [93/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [93/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [93/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [94/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [94/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [94/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [95/100], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [95/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [95/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [96/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [96/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [96/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [97/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [97/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [97/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [98/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [98/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [98/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [99/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [99/100], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [99/100], Loss: 0.0005, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "best_loss = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tlosses = []\n",
    "\tfor x, label in iter(test_dataloader):\n",
    "\t\tmodel.train()\n",
    "\n",
    "\t\t# Forward pass\n",
    "\t\tout = model(x)\n",
    "\t\tloss = criterion(out, label.float())\n",
    "\n",
    "\t\t# Backward and optimize\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tlosses.append(loss.item())\n",
    "\n",
    "\t\t# Compute accuracy\n",
    "\t\taccuracy = compute_accuracy(label, out)\n",
    "\n",
    "\t\tif loss.item() < best_loss:\n",
    "\t\t\tbest_loss = loss.item()\n",
    "\t\t\ttorch.save(model.state_dict(), \"best-model.bin\")\n",
    "\n",
    "\t\tprint(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\t\n",
    "\tavg_loss = sum(losses) / len(losses)\n",
    "\tall_losses.append(avg_loss)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3689256b30>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses\n",
    "\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin 1 01111000 Bin 2 11011110\n",
      "01111000 + 11011110 = 10011001\n",
      "30 + 123 = 153 ( 100.0 % correct)\n"
     ]
    }
   ],
   "source": [
    "# Use the best model to add two user predicted numbers\n",
    "\n",
    "model = Model()\n",
    "\n",
    "model.load_state_dict(torch.load(\"best-model.bin\"))\n",
    "\n",
    "# Get two numbers from the user\n",
    "n1 = int(input(\"Enter the first number: \"))\n",
    "n2 = int(input(\"Enter the second number: \"))\n",
    "\n",
    "input_sum = n1 + n2\n",
    "\n",
    "# Convert sum to binary\n",
    "sum_bin = bin(input_sum)[2:]\n",
    "\n",
    "# reverse the sum\n",
    "sum_bin = sum_bin[::-1]\n",
    "\n",
    "b1, b2 = convert_decimal_to_normalized_binary(n1, n2)\n",
    "\n",
    "print(\"Bin 1\", b1, \"Bin 2\", b2)\n",
    "\n",
    "numsT = torch.tensor([[int(x, 2) for x in b1], [int(x, 2) for x in b2]]).unsqueeze(0).float().transpose(1, 2)\n",
    "\n",
    "out = model(numsT)\n",
    "\n",
    "# round the output\n",
    "out = torch.round(out)\n",
    "\n",
    "# Convert the output to a string\n",
    "out_bin = \"\".join([str(int(x)) for x in out])\n",
    "out_deci = convert_normalized_binary_to_decimal(out_bin)\n",
    "\n",
    "\n",
    "# Compute percent diff between the sum and the model's output\n",
    "# By counting the number of digits correct\n",
    "correct = 0\n",
    "for i in range(len(sum_bin)):\n",
    "    if sum_bin[i] == out_bin[i]:\n",
    "        correct += 1\n",
    "percent_correct = correct / len(sum_bin)\n",
    "\n",
    "print(b1, \"+\", b2, \"=\", out_bin)\n",
    "\n",
    "print(n1, \"+\", n2, \"=\", out_deci, \"(\", percent_correct * 100, \"% correct)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 5]) torch.Size([128, 5])\n",
      "Input tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Sum tensor([1, 1, 0, 1, 0])\n",
      "Output tensor([0.6085, 0.5913, 0.5762, 0.5631, 0.5631], grad_fn=<SelectBackward0>)\n",
      "0.503125\n",
      "Epoch [0/100], Loss: 0.7070, Accuracy: 50.31%\n",
      "Epoch [0/100], Loss: 0.7555, Accuracy: 49.69%\n",
      "Epoch [0/100], Loss: 0.6935, Accuracy: 52.26%\n",
      "Epoch [1/100], Loss: 0.7176, Accuracy: 50.31%\n",
      "Epoch [1/100], Loss: 0.6984, Accuracy: 51.25%\n",
      "Epoch [1/100], Loss: 0.7008, Accuracy: 51.13%\n",
      "Epoch [2/100], Loss: 0.6997, Accuracy: 48.59%\n",
      "Epoch [2/100], Loss: 0.6924, Accuracy: 50.47%\n",
      "Epoch [2/100], Loss: 0.6922, Accuracy: 51.61%\n",
      "Epoch [3/100], Loss: 0.7007, Accuracy: 47.97%\n",
      "Epoch [3/100], Loss: 0.6870, Accuracy: 53.91%\n",
      "Epoch [3/100], Loss: 0.6945, Accuracy: 52.42%\n",
      "Epoch [4/100], Loss: 0.6935, Accuracy: 49.53%\n",
      "Epoch [4/100], Loss: 0.6899, Accuracy: 49.22%\n",
      "Epoch [4/100], Loss: 0.6895, Accuracy: 52.10%\n",
      "Epoch [5/100], Loss: 0.6875, Accuracy: 54.53%\n",
      "Epoch [5/100], Loss: 0.6865, Accuracy: 55.16%\n",
      "Epoch [5/100], Loss: 0.6884, Accuracy: 55.48%\n",
      "Epoch [6/100], Loss: 0.6840, Accuracy: 52.34%\n",
      "Epoch [6/100], Loss: 0.6845, Accuracy: 50.16%\n",
      "Epoch [6/100], Loss: 0.6860, Accuracy: 56.61%\n",
      "Epoch [7/100], Loss: 0.6729, Accuracy: 60.00%\n",
      "Epoch [7/100], Loss: 0.6796, Accuracy: 56.88%\n",
      "Epoch [7/100], Loss: 0.6855, Accuracy: 53.39%\n",
      "Epoch [8/100], Loss: 0.6671, Accuracy: 54.53%\n",
      "Epoch [8/100], Loss: 0.6777, Accuracy: 52.03%\n",
      "Epoch [8/100], Loss: 0.6780, Accuracy: 59.03%\n",
      "Epoch [9/100], Loss: 0.6591, Accuracy: 63.12%\n",
      "Epoch [9/100], Loss: 0.6683, Accuracy: 59.22%\n",
      "Epoch [9/100], Loss: 0.6775, Accuracy: 55.16%\n",
      "Epoch [10/100], Loss: 0.6494, Accuracy: 61.25%\n",
      "Epoch [10/100], Loss: 0.6608, Accuracy: 61.25%\n",
      "Epoch [10/100], Loss: 0.6739, Accuracy: 56.61%\n",
      "Epoch [11/100], Loss: 0.6356, Accuracy: 62.34%\n",
      "Epoch [11/100], Loss: 0.6800, Accuracy: 62.81%\n",
      "Epoch [11/100], Loss: 0.6735, Accuracy: 56.94%\n",
      "Epoch [12/100], Loss: 0.6443, Accuracy: 63.91%\n",
      "Epoch [12/100], Loss: 0.6535, Accuracy: 63.12%\n",
      "Epoch [12/100], Loss: 0.6656, Accuracy: 60.97%\n",
      "Epoch [13/100], Loss: 0.6412, Accuracy: 62.34%\n",
      "Epoch [13/100], Loss: 0.6381, Accuracy: 61.56%\n",
      "Epoch [13/100], Loss: 0.6651, Accuracy: 56.94%\n",
      "Epoch [14/100], Loss: 0.6275, Accuracy: 73.12%\n",
      "Epoch [14/100], Loss: 0.6245, Accuracy: 73.12%\n",
      "Epoch [14/100], Loss: 0.6451, Accuracy: 61.29%\n",
      "Epoch [15/100], Loss: 0.5966, Accuracy: 66.25%\n",
      "Epoch [15/100], Loss: 0.5896, Accuracy: 63.75%\n",
      "Epoch [15/100], Loss: 0.6303, Accuracy: 63.55%\n",
      "Epoch [16/100], Loss: 0.5572, Accuracy: 75.78%\n",
      "Epoch [16/100], Loss: 0.5514, Accuracy: 80.00%\n",
      "Epoch [16/100], Loss: 0.5847, Accuracy: 70.00%\n",
      "Epoch [17/100], Loss: 0.5033, Accuracy: 83.59%\n",
      "Epoch [17/100], Loss: 0.4958, Accuracy: 81.09%\n",
      "Epoch [17/100], Loss: 0.5358, Accuracy: 76.77%\n",
      "Epoch [18/100], Loss: 0.4810, Accuracy: 82.66%\n",
      "Epoch [18/100], Loss: 0.4588, Accuracy: 80.94%\n",
      "Epoch [18/100], Loss: 0.5122, Accuracy: 79.68%\n",
      "Epoch [19/100], Loss: 0.4065, Accuracy: 84.69%\n",
      "Epoch [19/100], Loss: 0.4346, Accuracy: 80.94%\n",
      "Epoch [19/100], Loss: 0.4514, Accuracy: 78.87%\n",
      "Epoch [20/100], Loss: 0.3515, Accuracy: 88.44%\n",
      "Epoch [20/100], Loss: 0.3603, Accuracy: 85.78%\n",
      "Epoch [20/100], Loss: 0.3800, Accuracy: 83.71%\n",
      "Epoch [21/100], Loss: 0.3532, Accuracy: 85.62%\n",
      "Epoch [21/100], Loss: 0.3288, Accuracy: 85.47%\n",
      "Epoch [21/100], Loss: 0.3236, Accuracy: 85.16%\n",
      "Epoch [22/100], Loss: 0.2796, Accuracy: 86.72%\n",
      "Epoch [22/100], Loss: 0.2630, Accuracy: 89.53%\n",
      "Epoch [22/100], Loss: 0.2474, Accuracy: 89.35%\n",
      "Epoch [23/100], Loss: 0.2050, Accuracy: 90.94%\n",
      "Epoch [23/100], Loss: 0.1985, Accuracy: 91.41%\n",
      "Epoch [23/100], Loss: 0.1952, Accuracy: 90.32%\n",
      "Epoch [24/100], Loss: 0.1612, Accuracy: 91.09%\n",
      "Epoch [24/100], Loss: 0.1853, Accuracy: 89.69%\n",
      "Epoch [24/100], Loss: 0.1461, Accuracy: 91.61%\n",
      "Epoch [25/100], Loss: 0.1380, Accuracy: 94.84%\n",
      "Epoch [25/100], Loss: 0.1201, Accuracy: 93.59%\n",
      "Epoch [25/100], Loss: 0.1055, Accuracy: 95.16%\n",
      "Epoch [26/100], Loss: 0.0872, Accuracy: 98.12%\n",
      "Epoch [26/100], Loss: 0.1021, Accuracy: 97.66%\n",
      "Epoch [26/100], Loss: 0.0664, Accuracy: 100.00%\n",
      "Epoch [27/100], Loss: 0.1035, Accuracy: 98.75%\n",
      "Epoch [27/100], Loss: 0.0460, Accuracy: 100.00%\n",
      "Epoch [27/100], Loss: 0.0728, Accuracy: 98.71%\n",
      "Epoch [28/100], Loss: 0.0354, Accuracy: 100.00%\n",
      "Epoch [28/100], Loss: 0.0553, Accuracy: 100.00%\n",
      "Epoch [28/100], Loss: 0.0600, Accuracy: 99.35%\n",
      "Epoch [29/100], Loss: 0.0333, Accuracy: 100.00%\n",
      "Epoch [29/100], Loss: 0.0290, Accuracy: 100.00%\n",
      "Epoch [29/100], Loss: 0.0588, Accuracy: 99.35%\n",
      "Epoch [30/100], Loss: 0.0237, Accuracy: 100.00%\n",
      "Epoch [30/100], Loss: 0.0206, Accuracy: 100.00%\n",
      "Epoch [30/100], Loss: 0.0208, Accuracy: 100.00%\n",
      "Epoch [31/100], Loss: 0.0185, Accuracy: 100.00%\n",
      "Epoch [31/100], Loss: 0.0211, Accuracy: 100.00%\n",
      "Epoch [31/100], Loss: 0.0216, Accuracy: 100.00%\n",
      "Epoch [32/100], Loss: 0.0173, Accuracy: 100.00%\n",
      "Epoch [32/100], Loss: 0.0149, Accuracy: 100.00%\n",
      "Epoch [32/100], Loss: 0.0156, Accuracy: 100.00%\n",
      "Epoch [33/100], Loss: 0.0126, Accuracy: 100.00%\n",
      "Epoch [33/100], Loss: 0.0128, Accuracy: 100.00%\n",
      "Epoch [33/100], Loss: 0.0148, Accuracy: 100.00%\n",
      "Epoch [34/100], Loss: 0.0121, Accuracy: 100.00%\n",
      "Epoch [34/100], Loss: 0.0108, Accuracy: 100.00%\n",
      "Epoch [34/100], Loss: 0.0118, Accuracy: 100.00%\n",
      "Epoch [35/100], Loss: 0.0088, Accuracy: 100.00%\n",
      "Epoch [35/100], Loss: 0.0085, Accuracy: 100.00%\n",
      "Epoch [35/100], Loss: 0.0102, Accuracy: 100.00%\n",
      "Epoch [36/100], Loss: 0.0079, Accuracy: 100.00%\n",
      "Epoch [36/100], Loss: 0.0079, Accuracy: 100.00%\n",
      "Epoch [36/100], Loss: 0.0094, Accuracy: 100.00%\n",
      "Epoch [37/100], Loss: 0.0074, Accuracy: 100.00%\n",
      "Epoch [37/100], Loss: 0.0075, Accuracy: 100.00%\n",
      "Epoch [37/100], Loss: 0.0087, Accuracy: 100.00%\n",
      "Epoch [38/100], Loss: 0.0067, Accuracy: 100.00%\n",
      "Epoch [38/100], Loss: 0.0068, Accuracy: 100.00%\n",
      "Epoch [38/100], Loss: 0.0080, Accuracy: 100.00%\n",
      "Epoch [39/100], Loss: 0.0061, Accuracy: 100.00%\n",
      "Epoch [39/100], Loss: 0.0063, Accuracy: 100.00%\n",
      "Epoch [39/100], Loss: 0.0075, Accuracy: 100.00%\n",
      "Epoch [40/100], Loss: 0.0057, Accuracy: 100.00%\n",
      "Epoch [40/100], Loss: 0.0059, Accuracy: 100.00%\n",
      "Epoch [40/100], Loss: 0.0071, Accuracy: 100.00%\n",
      "Epoch [41/100], Loss: 0.0054, Accuracy: 100.00%\n",
      "Epoch [41/100], Loss: 0.0056, Accuracy: 100.00%\n",
      "Epoch [41/100], Loss: 0.0068, Accuracy: 100.00%\n",
      "Epoch [42/100], Loss: 0.0051, Accuracy: 100.00%\n",
      "Epoch [42/100], Loss: 0.0053, Accuracy: 100.00%\n",
      "Epoch [42/100], Loss: 0.0065, Accuracy: 100.00%\n",
      "Epoch [43/100], Loss: 0.0048, Accuracy: 100.00%\n",
      "Epoch [43/100], Loss: 0.0050, Accuracy: 100.00%\n",
      "Epoch [43/100], Loss: 0.0062, Accuracy: 100.00%\n",
      "Epoch [44/100], Loss: 0.0046, Accuracy: 100.00%\n",
      "Epoch [44/100], Loss: 0.0048, Accuracy: 100.00%\n",
      "Epoch [44/100], Loss: 0.0060, Accuracy: 100.00%\n",
      "Epoch [45/100], Loss: 0.0044, Accuracy: 100.00%\n",
      "Epoch [45/100], Loss: 0.0046, Accuracy: 100.00%\n",
      "Epoch [45/100], Loss: 0.0058, Accuracy: 100.00%\n",
      "Epoch [46/100], Loss: 0.0043, Accuracy: 100.00%\n",
      "Epoch [46/100], Loss: 0.0044, Accuracy: 100.00%\n",
      "Epoch [46/100], Loss: 0.0057, Accuracy: 100.00%\n",
      "Epoch [47/100], Loss: 0.0041, Accuracy: 100.00%\n",
      "Epoch [47/100], Loss: 0.0042, Accuracy: 100.00%\n",
      "Epoch [47/100], Loss: 0.0055, Accuracy: 100.00%\n",
      "Epoch [48/100], Loss: 0.0040, Accuracy: 100.00%\n",
      "Epoch [48/100], Loss: 0.0041, Accuracy: 100.00%\n",
      "Epoch [48/100], Loss: 0.0054, Accuracy: 100.00%\n",
      "Epoch [49/100], Loss: 0.0039, Accuracy: 100.00%\n",
      "Epoch [49/100], Loss: 0.0040, Accuracy: 100.00%\n",
      "Epoch [49/100], Loss: 0.0052, Accuracy: 100.00%\n",
      "Epoch [50/100], Loss: 0.0038, Accuracy: 100.00%\n",
      "Epoch [50/100], Loss: 0.0038, Accuracy: 100.00%\n",
      "Epoch [50/100], Loss: 0.0051, Accuracy: 100.00%\n",
      "Epoch [51/100], Loss: 0.0037, Accuracy: 100.00%\n",
      "Epoch [51/100], Loss: 0.0037, Accuracy: 100.00%\n",
      "Epoch [51/100], Loss: 0.0049, Accuracy: 100.00%\n",
      "Epoch [52/100], Loss: 0.0036, Accuracy: 100.00%\n",
      "Epoch [52/100], Loss: 0.0036, Accuracy: 100.00%\n",
      "Epoch [52/100], Loss: 0.0048, Accuracy: 100.00%\n",
      "Epoch [53/100], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [53/100], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [53/100], Loss: 0.0047, Accuracy: 100.00%\n",
      "Epoch [54/100], Loss: 0.0034, Accuracy: 100.00%\n",
      "Epoch [54/100], Loss: 0.0034, Accuracy: 100.00%\n",
      "Epoch [54/100], Loss: 0.0046, Accuracy: 100.00%\n",
      "Epoch [55/100], Loss: 0.0033, Accuracy: 100.00%\n",
      "Epoch [55/100], Loss: 0.0034, Accuracy: 100.00%\n",
      "Epoch [55/100], Loss: 0.0045, Accuracy: 100.00%\n",
      "Epoch [56/100], Loss: 0.0032, Accuracy: 100.00%\n",
      "Epoch [56/100], Loss: 0.0033, Accuracy: 100.00%\n",
      "Epoch [56/100], Loss: 0.0044, Accuracy: 100.00%\n",
      "Epoch [57/100], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [57/100], Loss: 0.0032, Accuracy: 100.00%\n",
      "Epoch [57/100], Loss: 0.0043, Accuracy: 100.00%\n",
      "Epoch [58/100], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [58/100], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [58/100], Loss: 0.0042, Accuracy: 100.00%\n",
      "Epoch [59/100], Loss: 0.0030, Accuracy: 100.00%\n",
      "Epoch [59/100], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [59/100], Loss: 0.0041, Accuracy: 100.00%\n",
      "Epoch [60/100], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [60/100], Loss: 0.0030, Accuracy: 100.00%\n",
      "Epoch [60/100], Loss: 0.0040, Accuracy: 100.00%\n",
      "Epoch [61/100], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [61/100], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [61/100], Loss: 0.0039, Accuracy: 100.00%\n",
      "Epoch [62/100], Loss: 0.0028, Accuracy: 100.00%\n",
      "Epoch [62/100], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [62/100], Loss: 0.0038, Accuracy: 100.00%\n",
      "Epoch [63/100], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [63/100], Loss: 0.0028, Accuracy: 100.00%\n",
      "Epoch [63/100], Loss: 0.0038, Accuracy: 100.00%\n",
      "Epoch [64/100], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [64/100], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [64/100], Loss: 0.0037, Accuracy: 100.00%\n",
      "Epoch [65/100], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [65/100], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [65/100], Loss: 0.0036, Accuracy: 100.00%\n",
      "Epoch [66/100], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [66/100], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [66/100], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [67/100], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [67/100], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [67/100], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [68/100], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [68/100], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [68/100], Loss: 0.0034, Accuracy: 100.00%\n",
      "Epoch [69/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [69/100], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [69/100], Loss: 0.0033, Accuracy: 100.00%\n",
      "Epoch [70/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [70/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [70/100], Loss: 0.0033, Accuracy: 100.00%\n",
      "Epoch [71/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [71/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [71/100], Loss: 0.0032, Accuracy: 100.00%\n",
      "Epoch [72/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [72/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [72/100], Loss: 0.0032, Accuracy: 100.00%\n",
      "Epoch [73/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [73/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [73/100], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [74/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [74/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [74/100], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [75/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [75/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [75/100], Loss: 0.0030, Accuracy: 100.00%\n",
      "Epoch [76/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [76/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [76/100], Loss: 0.0030, Accuracy: 100.00%\n",
      "Epoch [77/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [77/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [77/100], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [78/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [78/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [78/100], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [79/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [79/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [79/100], Loss: 0.0028, Accuracy: 100.00%\n",
      "Epoch [80/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [80/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [80/100], Loss: 0.0028, Accuracy: 100.00%\n",
      "Epoch [81/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [81/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [81/100], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [82/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [82/100], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [82/100], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [83/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [83/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [83/100], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [84/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [84/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [84/100], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [85/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [85/100], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [85/100], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [86/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [86/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [86/100], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [87/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [87/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [87/100], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [88/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [88/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [88/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [89/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [89/100], Loss: 0.0018, Accuracy: 100.00%\n",
      "Epoch [89/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [90/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [90/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [90/100], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [91/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [91/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [91/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [92/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [92/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [92/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [93/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [93/100], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [93/100], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [94/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [94/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [94/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [95/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [95/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [95/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [96/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [96/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [96/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [97/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [97/100], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [97/100], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [98/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [98/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [98/100], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [99/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [99/100], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [99/100], Loss: 0.0021, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# This model memorizes\n",
    "\n",
    "data = BinaryDataset(3 * 128, 5)\n",
    "test_dataloader = DataLoader(dataset=data, batch_size=128)\n",
    "\n",
    "\n",
    "# Make model \n",
    "# Define the model\n",
    "class MemModel(nn.Module):\n",
    "\tdef __init__(self) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.input_size = 2 # Passing two binary bits\n",
    "\t\tself.hidden_dim = 10\n",
    "\t\tself.output_size = 1 # Returning 1 bit binary sum\n",
    "\t\t\n",
    "\t\tself.rnn = nn.RNN(\n",
    "\t\t\tinput_size=self.input_size,\n",
    "\t\t\thidden_size=self.hidden_dim, \n",
    "\t\t\tbatch_first=True\n",
    "\t\t)\n",
    "\t\tself.fc = nn.Linear(self.hidden_dim, self.output_size)\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# hidden = self.init_hidden(batch_size)\n",
    "\n",
    "\t\t# X is of size (batch_size, sequence_length, input_dim = 2)\n",
    "\t\t# hidden is of size (n_layers, sequence_length, hidden_dim)\n",
    "\t\tout, hidden = self.rnn(x)\n",
    "\n",
    "\t\tout, _ = self.rnn(x, hidden)\n",
    "\n",
    "\t\tout = self.fc(out)\n",
    "\n",
    "\t\tout = self.sigmoid(out)\n",
    "\n",
    "\t\t# Out is now of shape (batch_size, sequence_length, output_dim = 1)\n",
    "\n",
    "\t\tout = out.squeeze()\n",
    "\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = MemModel()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "# Test the model's accuracy\n",
    "def compute_accuracy(label, pred):\n",
    "\tpred = torch.round(pred)\n",
    "\t# Pred is of size (batch_size, sequence_length)\n",
    "\t# Label is of size (batch_size, sequence_length)\n",
    "\treturn torch.sum(label == pred).item() / (len(label) * len(label[0]))\n",
    "\n",
    "\n",
    "# Try the model on random data\n",
    "x, label = next(iter(test_dataloader))\n",
    "out = model(x)\n",
    "print(out.shape, label.shape)\n",
    "print(\"Input\", x[0])\n",
    "print(\"Sum\",  label[0])\n",
    "print(\"Output\", out[0])\n",
    "print(compute_accuracy(label, out))\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "best_loss = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tlosses = []\n",
    "\tfor x, label in iter(test_dataloader):\n",
    "\t\tmodel.train()\n",
    "\n",
    "\t\t# Forward pass\n",
    "\t\tout = model(x)\n",
    "\t\tloss = criterion(out, label.float())\n",
    "\n",
    "\t\t# Backward and optimize\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tlosses.append(loss.item())\n",
    "\n",
    "\t\t# Compute accuracy\n",
    "\t\taccuracy = compute_accuracy(label, out)\n",
    "\n",
    "\t\tif loss.item() < best_loss:\n",
    "\t\t\tbest_loss = loss.item()\n",
    "\t\t\ttorch.save(model.state_dict(), \"best-model-2.bin\")\n",
    "\n",
    "\t\tprint(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\t\n",
    "\tavg_loss = sum(losses) / len(losses)\n",
    "\tall_losses.append(avg_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
